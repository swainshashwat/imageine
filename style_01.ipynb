{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-15f580720011>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2511e7f244ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from scipy.optimize import fmin_l_bfgs_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "c_im_path = 'data/megan_fox.jpg'\n",
    "s_im_path = 'data/melodyonight.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target dims\n",
    "targetHeight = 512\n",
    "targetWidth = 512\n",
    "targetSize = (targetHeight, targetWidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess(img_path,\n",
    "                    targetSize=targetSize):\n",
    "    '''\n",
    "    Loads image as PIL.image, converts into np.ndarray\n",
    "        then preprocesses it as a Vgg16 input shape\n",
    "        after expanding row dimension by1\n",
    "    '''\n",
    "    im = load_img(path=img_path,\n",
    "                     target_size=targetSize)\n",
    "    im_arr = img_to_array(im)\n",
    "    im_arr = K.variable(preprocess_input(\n",
    "                            np.expand_dims(im_arr, axis=0)),\n",
    "                            dtype='float32')\n",
    "    return im_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cImArr = load_preprocess(c_im_path) # content image\n",
    "sImArr = load_preprocess(s_im_path) # style image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gIm0 = np.random.randint(256,\n",
    "                size=(targetWidth, targetHeight, 3)).astype('float64')\n",
    "gIm0 = preprocess_input(np.expand_dims(g_im_0, axis=0))\n",
    "gImPlaceholder = K.placeholder(\n",
    "        shape=(1, targetWidth, targetHeight, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_reps(x, layer_names, model):\n",
    "    '''\n",
    "    Get feature representations of\n",
    "    input x for one or more layers in a given model.\n",
    "    '''\n",
    "    featMatrices = []\n",
    "    for ln in layer_names: # iterate through layers\n",
    "        selectedLayer = model.get_layer(ln)\n",
    "        featRaw = selectedLayer.output\n",
    "        featRawShape = K.shape(featRaw).eval(session=tf_session)\n",
    "        \n",
    "        # rows\n",
    "        N_1 = featRawShape[-1] \n",
    "        # columns\n",
    "        M_1 = featRawShape[1]*featRawShape[2] # height * width\n",
    "        \n",
    "        featMatrix = K.reshape(featRaw, (M_1, N_1))\n",
    "        featMatrix = K.transpose(featMatrix)\n",
    "        \n",
    "        featMatrices.append(featMatrix)\n",
    "        \n",
    "    return featMatrices      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_loss(F, P):\n",
    "    cLoss = 0.5*K.sum(K.square(F - P))\n",
    "    return cLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Gram_matrix(F):\n",
    "    G = K.dot(F, K.transpose(F))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_style_loss(ws, Gs, As):\n",
    "    sLoss = K.variable(0.)\n",
    "    for w, G, A in zip(ws, Gs, As):\n",
    "        M_1 = K.int_shape(G)[1]\n",
    "        N_1 = K.int_shape(G)[0]\n",
    "        \n",
    "        G_gram = get_Gram_matrix(G)\n",
    "        A_gram = get_Gram_matrix(A)\n",
    "        \n",
    "        norm_fact = N_1**2 * M_1**2\n",
    "        weight_sum = w*0.25*K.sum(K.square(G_gram - A_gram))\n",
    "        sLoss+= weight_sum / norm_fact\n",
    "    \n",
    "    return sLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_loss(gImPlaceholder, alpha=1.0, beta=1000.0):\n",
    "    \"\"\"\n",
    "    Total Style Transfer Loss function.\n",
    "    alpha: Adjusts weight of the content Loss\n",
    "    beta: Adjusts weight of the style Loss\n",
    "    \"\"\"\n",
    "    F = get_feature_reps(gImPlaceholder,\n",
    "                         layer_names=[cLayerName],\n",
    "                        model = gModel)[0]\n",
    "    Gs = get_feature_reps(gImPlaceholder,\n",
    "                         layer_names=sLayerNames,\n",
    "                         model=gModel)\n",
    "    # content loss\n",
    "    contentLoss = get_content_loss(F, P)\n",
    "    \n",
    "    # style loss\n",
    "    styleLoss = get_style_loss(ws, Gs, As)\n",
    "    \n",
    "    # weighted loss\n",
    "    totalLoss = alpha*contentLoss + beta*styleLoss\n",
    "    \n",
    "    return totalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(gImArr):\n",
    "    \"\"\"\n",
    "    Calculate total loss\n",
    "    \"\"\"\n",
    "    if gImArr.shape != (1, targetWidth, targetHeight, 3):\n",
    "        gImArr = gImArr.reshape((1, targetWidth, targetWidth, 3))\n",
    "    loss_fcn = K.function([gModel.input], \n",
    "                          [get_total_loss(gModel.input)])\n",
    "    return loss_fcn([gImArr])[0].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad(gImArr):\n",
    "    \"\"\"\n",
    "    Calculate the gradient of the loss function\n",
    "    with respect to the generated image\n",
    "    \"\"\"\n",
    "    if gImArr.shape != (1, targetWidth, targetHeight, 3):\n",
    "        gImArr = gImArr.reshape((1, targetWidth, targetHeight, 3))\n",
    "    grad_fcn = K.function([gModel.input],\n",
    "                         K.gradients(\n",
    "                             get_total_loss(\n",
    "                                 gModel.input), [gModel.input]))\n",
    "    \n",
    "    grad = grad_fcn([gImArr])[0].flatten().astype('float64')\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor session\n",
    "tf_session = K.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cModel = VGG16(include_top=False,\n",
    "               weights='imagenet',\n",
    "              input_tensor=cImArr)\n",
    "sModel = VGG16(include_top=False,\n",
    "                weights='imagenet',\n",
    "              input_tensor=sImArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "gModel = VGG16(include_top=False,\n",
    "                weights='imagenet',\n",
    "              input_tensor=gImPlaceholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cLayerName = 'block4_conv2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sLayerNames = [\n",
    "    'block1_conv1',\n",
    "    'block2_conv1',\n",
    "    'block3_conv1',\n",
    "    'block4_conv1'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = get_feature_reps(x=cImArr,\n",
    "                     layer_names=[cLayerName],\n",
    "                    model=cModel)[0]\n",
    "As = get_feature_reps(x=sImArr,\n",
    "                     layer_names=sLayerNames,\n",
    "                     model=sModel)\n",
    "ws = np.ones(len(sLayerNames))/float(len(sLayerNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "iterations = 600\n",
    "x_val = gIm0.flatten()\n",
    "xopt, f_val, info = fmin_l_bfgs_b(calculate_loss,\n",
    "                                  x_val,\n",
    "                                  fprime=get_grad,\n",
    "                                  maxiter=iterations,\n",
    "                                  disp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
